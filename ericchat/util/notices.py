
def get_smol_3b_notice():

    notice = """
    Recommended memory: ~5 GB
    
    Description: An MLX quantized version of HuggingFaceTB/SmolLM3-3B (https://huggingface.co/HuggingFaceTB/SmolLM3-3B)

    URL: https://huggingface.co/EricFillion/smollm3-3b-mlx

    License: Apache 2.0 (https://choosealicense.com/licenses/apache-2.0/) 

    """

    return notice


def get_gpt_oss_20b_notice():
    notice = """
    Recommended memory: ~14 GB 
        
    Description: An MLX quantized version of openai/gpt-oss-20b (https://huggingface.co/openai/gpt-oss-20b)

    URL: https://huggingface.co/EricFillion/gpt-oss-20b-mlx
    
    License: Apache 2.0 (https://choosealicense.com/licenses/apache-2.0/)

    """

    return notice



def get_gpt_oss_120b_notice():
    notice = """
    Recommended memory: ~60 GB 
    
    Description: An MLX quantized version of openai/gpt-oss-120b (https://huggingface.co/openai/gpt-oss-120b)

    URL: https://huggingface.co/EricFillion/gpt-oss-120b-mlx

    License: Apache 2.0 (https://choosealicense.com/licenses/apache-2.0/)
    
    """

    return notice